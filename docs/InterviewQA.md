#### Java面试可能遇见的那个它

##### Java核心技术

+ 一个空对象多大内存？
  > 在hotspot虚拟的实现里一个对象对应内存布局采用OOP结构，主要有三个部分：对象头、实例数据、对齐填充。而对象头又包括三部分：对象头（MarkWord）、类（元数据）指针、数组长度！
  > + 对象头：用于存储对象运行时的数据，好比 HashCode、锁状态标志、GC分代年龄等，在64位操作系统中占用 __8个字节__，32位中占用 __4个字节__
  > + 指针：用来指向当前实例所归属的类实例指针，这里会涉及对指针的压缩处理，在开启指针压缩的状况下占 __4个字节__，未开启状况下占 __8个字节__
  > + 数组长度：这部分只有是数组对象才有，这部分占 __4个字节__
  >
  > 所谓的对齐填充，就是Java 对象的大小默认都是按照 __8个字节__ 对齐，也就是说Java对象的大小必须是 __8个字节__ 的倍数。若是算到最后不够 __8个字节__ 的话，那么就会进行对齐填充！
  > 为啥非要进行 __8个字节__ 填充处理？看起来是对空间的一种浪费！这么做的原因是由于 CPU 进行内存访问时，一次寻址的指针大小是 __8个字节__，正好也是 L1 缓存行的大小。
  > 如果不进行内存对齐，则可能出现跨缓存行的情况，进而造成`缓存行污染`。 所以很容易就能算出来一个空对象所占用的内存大小正好就是 __16个字节__。


+ 为什么需要包装类型？int与Integer的区别？
  > + __原因：__
      因为Java本身就是一门面向对象的语言，对象是Java的基础操作单元。很多时候传递数据也需要对象类型，比如`ArrayList`、
      `HashMap`这些集合，只能存储对象类型，因此封装类型存在的意义就很大。封装类型还有很多好处，比如安全性较好，
      可以避免外部操作随意修改成员变量的值，保证了成员变量和数据传递的安全性！
  > + __区别：__
  >  + Integer的初始值是`null`，int的初始值是0;
  >  + Integer存储在堆内存中，int直接存储在栈空间；
  >  + Integer是对象类型，它封装了很多方法和属性。

+ “==” 和 “equals()” 有什么区别，为什么重写“equals()”时也要重写“hashcode()”方法？
  > 首先这两个比较操作存在着本质上的区别，“==” 判断的时引用地址（内存地址）的一致性，但是 “equals” 更偏向于判断对象的数据信息一致性，
  > 而且 “equals” 方法的第一行代码优先采用 “==” 作为判断！有些时候我们会重写 “equals” 方法来个性化判断对象是否相等，在这个重写的过程中，
  > 我们都知道也需要重写 “hashcode” 方法，可是为什么呢？原因是 `hashcode` 会被用来在集合类中查找定位元素，
  > 然而在jdk中默认通过随机数算法来生成 `hashcode`，势必会导致两个不同的对象可能会存在相同的 `hashcode`。
  > 假如仅重写了 “equals“ 而不重写 “hashcode“ 方法，就会造成集合类在存储和查找元素时，完全相同的对象因为 `hashcode` 被存储在了两个不同位置。
  > 这与事实是相违背的，所以提倡 “equals“ 与 ”hashcode“ 一起进行重写，这里也可以得到一个结论：两个完全相同的对象，它们的 `hashcode` 一定相同！

+ 关于HashMap如何解决hash冲突、如何进行内存扩容，底层数据结构的优缺点问题？
  > JDK1.7 采用了冲突链表解决 hash 冲突，JDK1.8 则采用链表加红黑树的方式解决 hash 冲突，链表长度大于 8 且元素个数达到 64 个时会转化为红黑树，当链表的个数小于 8 时变回链表
  > JDK1.7 扩容采用了头插法，并发环境下使用会导致`死循环`问题，对于一个`A->B-C` 的链会被反转为 `B->C->A`。 

+ ConcurrentHashMap实现原理，它与HashMap有啥区别和不同？
+ ArrayList是如何实现自动扩容的？
+ CopyOnWriteArrayList是如何实现的，与ArrayList的区别？
+ AtomicInteger高并发下的性能问题？
  > 因为多线程同时进行数据修改，底层通过unsafe的CAS机制实现，会造成频繁的空循环问题，使用不当会造成cpu飙升！
  > 可以考虑通过`LongAddr`来避免，在`LongAddr`内部维护了一个数组，当出现并发操作进行多次修改后，
  > 会为每个线程分配一个单独的`AtomicLong`进行修改操作，避免了多个线程操作同一个值造成的性能问题（空循环）！

+ ThreadLocal的使用及原理，内存泄露的原因？
+ ThreadPoolExecutor的执行过程及原理？
+ 为什么不建议通过Executors创建线程池，如何定制线程池参数？
+ ForkJoinPool如何工作的，特点是啥？
+ ThreadPoolExecutor和ForkJoinPool的区别是啥，为什么要设计他们？
+ 同步队列有几种？各有什么特点，使用场景有那些？
+ 你是如何看待指令重排序问题的？
  > 操作系统通过对操作指令进行重新排序后不影响程序执行结果，从而提升程序执行的效率的一种手段。
  > 例如一个 Java 对象创建的过程中需要经历：1）内存分配、2）实例数据初始化、3）引用赋值三个步骤，
  > 当对 2，3 步骤进行顺序调换后，一般情况下并不会对程序的执行结果造成影响，然而在多线程的环境下是会存在问题的（例如：DCL下的单例实现），
  > 会导致线程在使用对象时，可能对象的属性还没有完成数据初始化造成不可预见的错误，可能存在的现象有：代码空指针异常问题、逻辑分支判断错误等！

+ Lock的使用问题？
+ 为什么会出现AQS，AQS的实现机制是怎样的，通过它可以干什么？
  > AQS是一种用于多线程队列同步器，JUC包中很多同步组件类都基于AQS进行实现。

+ 什么条件下会产生死锁，如何避免死锁？
  > 死锁的概念：当两个或两个以上的线程在执行过程中，去争夺同一个共享资源而导致相互等待的现象。
  > 产生死锁需要同时满足以下 4 个条件：
  > + 互斥条件：即一个共享资源只能被一个线程占用。
  > + 不可剥夺条件：当一个线程已经获得了共享资源 A，再去请求共享资源 B 的时候，不会释放目前已经占有的共享资源 A。
  > + 不可抢占条件：其他线程不能强行抢占一个线程已占有的共享资源。
  > + 循环等待条件：对于共享资源 A、B，线程 T1 已获得共享资源 A 等待共享资源 B，而线程 T2 已获得共享资源 B 等待共享资源 A，形成了循环等待。
  > 
  > 死锁的发生会影响程序的正确执行结果和服务的性能，那么如何避免死锁呢？对于产生死锁的 4 个条件，互斥条件是无法进行破坏的，因为它是互斥锁的基本约束。
  > 但是其他三个条件都可以通过任务干预来破坏，那么死锁问题自然也就解除了。破坏的手段通常有以下几种方式：
  > + 破坏请求和保持条件：我们可以在首次执行时一次性申请所有的资源，这样就不存在互相等待锁行为了！
  > + 破坏不可抢占条件：占有部分共享资源的线程在进一步申请其他共享资源的时候，如果申请失败那么可以主动释放已申请占用的共享资源。
  > + 破坏循环等待条件：通过给共享资源进行编号，线程按照编号顺序来申请共享资源的方式来避免死锁的产生。

+ Synchronize如何实现的，它和Lock的区别是什么？

  > Synchronize 是通过 jvm 指令进行实现的，处于 Synchronize 中的代码块，在进行字节码转换的时会在代码块执行前后
  > 加入`monitorenter`，`monitorexit`指令。

+ 使用过JUC包下的那些类，工作中用它都做了什么？
+ 你怎么看待lambda表达式，JDK内部如何是如何进行实现的？
+ 实现动态代理的几种方式，如何看待动态代理？

  > 在java中实现动态代理有两种方式：1）JDK的动态代理，通过接口进行代理。2）javassist动态代理，通过继承的方式进行代理，
  > 无法实现`final`类的代理。动态代理的目的是实现类的增强机制，让我们可以在使用类之前对其增强发挥更加强大的作用。

+ Java中的IO类型有那些？NIO又是如何进行实现的？
+ lombok是如何工作的？
  > lombok 在开发中可以帮我简化 setter、 getter 方法生成，日志类的注入、toString 方法的生成都可以通过它提供的注解完成，简化了代码结构！
  > 这些特性和能力都是通过实现 java 中的注解处理器 `javax.annotation.processing.AbstractProcessor`，对类字节码或源文件进行增强处理！

+ 零拷贝是什么？如何实现它？
  > 当用户程序与 OS 发生之间 IO 操作时，会涉及内存数据与磁盘数据的读写交换，一次完整的 IO 处理一般需要 4 次数据拷贝才能完成并涉及用户态和内核态的切换，
  > 这个样的 IO 操作的性能底下，对于数据读写频繁的系统来说很不友好。为了优化 IO 性能降低数据拷贝的次数，进而提出了 ”零拷贝“ 技术！

##### JVM相关

+ JVM 内存模型是怎样的？
  > 主要分为以下部分：方法区（JDK8 后采用元空间替代）、运行池常量池、堆、虚拟机栈、程序计数器、本地方法栈。

+ 垃圾回收算法有哪几种？
  > + 标记清除算法：
  > + 复制算法：
  > + 标记整理算法：

+ 判断对象可以回收的依据是什么？有哪些手段？
  > 主要有两种判断方式：引用计数法、可达性分析。

+ GCRoot 是什么？
  > 对于 GCRoot 的选取，一般会使用当前处于活跃的对象为基准，可选择的范围有：虚拟机栈中引用的对象、方法区中引用的对象、本地方法栈中引用的对象。

+ G1 如何工作？
  > 不再以传统的方式进行内存分配，而是内存划分为指定大小区间的块（Region），通过块来完成内存的分配，采用标记清除 + 复制算法对垃圾对象进行回收。

+ ZGC 是如何实现的？
  > 采用了三色标记的技术。

##### 数据库技术

+ sql的执行过程及步骤？
+ mysql中的BufferPool机制？
+ mysql 中 InnoDB 与 MyISAM 引擎的区别？
  > + __存储结构__：MyISAM 在磁盘上存储为三个文件，分别是：.frm（存储表定义）、.myd（存储数据文件）、.myi（存储索引文件）。
  > InnoDB 仅存储为两个文件分别是：.frm（存储表定义）、.ibd（存储数据和索引文件）。
  > 通过文件分类可以看出，MyISAM 的数据和索引是分开存储的，叶子节点仅存储数据所在的地址而不是数据。
  > 而 InnoDB 则不同，叶子节点存储的是整个数据行所有的数据
  > + __存储空间__：MyISAM 可被压缩，存储空间较小，并支持三种不同的存储格式：静态表（默认，数据末尾不能存在空格，空格会被去掉）、动态表、压缩表。
  > InnoDB 则需要更多的内存和空间，它会在内存中建立自己专用的缓冲池（`buff_pool`）来高速缓冲数据和索引。
  > 同时 InnoDB 所有表都保存在同一个数据文件中（可能也是多个文件，或独立的表空间），数据表的大小取决于操作系统中文件的大小，一般为 2GB。
  > + __事务支持__：MyISAM 强调的是性能，每次查询都具有原子性，它的执行速度比 InnoDB 更快，但是提供事务支持。
  > InnoDB 除了提供事务支持和外部键等高级数据库功能，还具有事务提交、回滚和崩溃修复能力等这些事务安全功能。
  > + __锁支持__：MyISAM 在只是大量数据查询的场景中性能更好，增删数据的时候锁定的是整个数据表，效率会低很多。
  > InnoDB 支持行级锁、删除、插入的场景中只需要锁定需要操作的数据行即可，在有大量数据插入、修改、删除数据的场景中，性能更优越。
  > + __外键支持__：MyISAM 不支持外键，而 InnoDB 支持。

+ B树和B+树？
  > 

+ mysql 索引类型有哪些？
  > MySQL 有很多种类型的索引，例如：主键索引、唯一索引、联合索引、外键索引、普通索引、前缀索引等等。
  
+ 导致索引失效的场景有那些？
  > + 在索引列上做运算。当在数据列上使用函数时，会导致 mysql 无法识别索引列而不使用索引的情况。不过 mysql 8.0 版本开始，增加了函数索引，可以解决这个问题。
  > + 不符合最左匹配原则。当对联合索引的多个列进行数据查询时，应该按照这些列对应的联合索引顺序进行查询，按照最左匹配的原则进行查询，否则不会使用索引。
  > + 索引列的隐式转换。当索引列是字符串类型，而在执行查询的 sql 中没有使用引号，那么 mysql 会自动进行类型转化，从而导致索引失效。
  > + 索引列使用不等号、not 查询的时候。由于索引数据的检索效率非常低，因此 mysql 引擎会判断是否使用索引。
  > + 使用 like 通配符后缀匹配。如果我们在索引列上使用了 like 这种通配符进行查询，必须有要符合最左匹配的原则，否则不会使用到索引。
  > 例如 `"%xxx"` 不会使用索引，但是 `"xxx%"` 会使用索引进行查询。
  > + 使用 or 连接查询。or 语句前后没有同时使用索引，那么索引会失效。只有 or 语句的左右查询字段都是索引列的时候，才会生效。

+ mysql的MVCC机制原理？
  > 通过 undo_log、redo_log 机制来保存 DML 操作前后的数据快照信息，为数据库事务的回滚提供了基础。
  > 

+ 执行计划（explain）的内容都有什么？
+ 为什么需要进行分库分表？工作中如何实现分库分表？
+ 优化数据查询的方式有那些？
  > 对SQL的优化的方式有很多中，优化需要结合索引结构、数据结构、业务能力等多个方面而进行，否则我们的优化毫无意义！优化的方式有：
  > + 加索引：mysql表的索引不是越多越好，能够满足自身业务需求就好，不要盲目的去加索引
  > + 联合索引：当我们的业务场景中会使用到多个查询条件的时候，我们可以考虑对查询的多个条件建立联合索引
  > + 减少不必要字段的输出：编写 sql 查询语句时，一定要保持一个用什么查什么的习惯，切记一股脑的将所有字段列查询出来。这么做会占用数据库实例的带宽，数据IO的时长也增加
  > + 避免子查询：如果执行的 sql 存在子查询，那么执行时会建立一张临时表用于存储子查询的结果集，对于临时表的创建都会是一种性能上的消耗，查询的效率大大降低。
  > 优化方式有：1）拆分成两次独立查询，并结合 in 关键字进行优化；2）将子查询降级为 join 联合查询，但是并不建议这么做！
  > 
  > + 分库分表：当我们的数据量是千万级、亿级的话，单表查询就无法快速索引数据（毫秒级别），因为mysql采用了B+树的索引方式，当树的级别超过 3 层就会存在性能。
  > 一般建议单数据表记录数应该不超过 400w 左右，否则就应该采用分库分表的方式来优化数据存储。

+ 事务的隔离级别有哪些？
  > 事务隔离是了解决多个并行事务竞争导致的数据安全问题的一种规范，最终目的是保证事务执行结果的数据一致性！
  > 一共存在读未提交、读已提交、可重复读、串行化这四种事务隔离级别。下面针对各个级别的特点和所产生的问题进行详细介绍：
  > + __读未提交__：一个事务在执行过程中读取了另一个事务未提交的内容。这种隔离级别下，可能会出现脏读、不可重复读、幻读问题。
  > + __读已提交__：一个事务在执行的过程中，读取到了另一个事务已经提交的内容。这种隔离级别下会产生不可重复读、幻读问题。
  > + __可重复读__：一个事务执行过程中先后两次读取到另一个事务所操作的数据，两次读取的结果一致。这种隔离级别会出现幻读问题。
  > + __串行化__：并行事务的操作具有先后顺序，有序进行，这种隔离级别可以解决所有问题，但是性能也是最低的。
  > 
  > MySQL 的 InnoDB 引擎默认采用可重复读的隔离界别，并通过 MVCC、临键锁、undo_log、redo_log 保证事务的数据一致性问题。 

+ mysql中的锁有那些？
  > + __表锁__：锁定当前锁所操作的数据表
  > + __行锁__：会锁定当前所操作的记录
  > + __间隙锁__：锁定一个左开右开的区间，不包含当前记录行
  > + __临建锁__：是行锁与表锁的组合，锁定一个左开右闭的区间，包含了当前锁操作的记录行

##### 缓存技术

+ 为什么需要缓存？ 
  > 为了实现高性能、高并发、打造时延性更低的应用程序，通过引入缓存可以很好地解决这个问题。
  > 当程序中某些数据做查询时花费的时间很长（200ms+），但数据又不怎么变化的情况下，引入缓存是充分非必要的手段。
  > 而且缓存对于那些读远远高于写的业务场景来说简直就是一剂良。其实我们所接触的很多技术都有涉及对缓存的运用，
  > 例如：CPU的三级缓存、MySQL的buffer_pool机制，spring中使用到的三级缓存技术等等，都是为了更快地响应和处理数据而选择的技术方案。

+ 使用缓存会带来什么问题？
  > 虽然缓存能够提供更好的性能，我们任何事物都具有双面性，对于缓存而言也不列外。它的好也决定了在运用它的时候也会出现各种问题，常见的问题主要有：
  > + 缓存和数据库双写不一致
  > + 缓存雪崩、缓存穿透、缓存击穿
  > + 缓存并发竞争

+ 缓存雪崩、缓存穿透、缓存击穿分别指什么？如何进行避免呢？
  > 这三个问题在缓存使用场景中会常常被提到，接下来就针对这三个问题的场景及解决方案进行分讨论，首先看看产生这些问题的场景怎样的：
  > + __缓存雪崩__：整个缓存系统处于挂掉完全不可用状态，导致所有数据查询都不走缓存，而直接访问数据库的一种现象。
  > + __缓存穿透__：业务在进行数据查询时，查询了一个压根就不存在的数据无法命中缓存，每次都需要访问数据库的场景。
  > + __缓存击穿__：缓存中的某个热点key在某一时刻过期，后续对于这个key的高并发访问直接请求数据库，就像是在缓存的屏障开凿了一个洞一样。
  > 
  > 针对产生这些问题的现象和场景，我们应该从中找到突破口进行修复或者避免该问题的发生，从而提高缓存的安全性和可靠性。避免的手段与解决方案如下：
  > + __缓存雪崩__：1）通过主从、哨兵等方式搭建高可用的 redis 集群。
  > + __缓存穿透__：1）为查询不到的数据进行短暂的缓存，并设置过期时间进行缓冲。2）通过使用 redis 中的布隆过滤器进行判断
  > + __缓存击穿__：在进行数据缓存时，设置不同的过期值，同业务下的 key 通过对不同的数据 key 的过期时间加随机避免同时过期！

+ redis有哪些基本数据类型？
  > 主要有5大基本数据类型：字符串（String）、列表（list）、哈希表（hash）、无需集合（set）、有序集合（zset）。
  > 其次还有一些展类型例如：Bitmaps（位图）、HyperLogLog（一种概率数据结构，用于估计集合的基数）、Geospatial（地理位置信息）。
  > Bitmaps 与 HyperLogLog 都是基于 redis 中的 string 进行实现的。
  > + __字符串__：redis 没有采用 C 语言原生的 string 作为实现，而是定了一个 SDS 结构体作为底层实现，主要有三部分组成：len（长度）、free（空闲空间）、buf数组（真实数据）。
  > 在 C 语言中，字符串通过 `\0` 作为结束标记无法保存特殊字符，而 redis 可以做到，所以 redis 的 string 是一个 `二进制安全` 的数据结构，
  > 对于长度获取的时间复杂度为 O(1)，扩容无需频繁分配内存通过 free 属性做了 `空间预分配` 和 `惰性空间释放` 两个优化，修改时通过判断长度和空闲空间的大小来避免缓冲区溢出问题。
  > + __列表__：底层基于链表、压缩列表、快速列表来实现（各个不同的版本可能存在差异）。实际开发过程中，列表会被用做栈（stack）和队列（queue）的实现（使用频次高）。
  > 使用场景有：粉丝列表、评论列表、消息队列、高性能分页查询等。
  > + __哈希表__：通过压缩链表或者哈希表（字典）来进行实现。当数据量比较大时，不建议采用 `getAll` 来全部数据应该使用 `scan` 模式进行替换。
  > 使用场景有：用户核心信息、某些对象的高频数据等，只要用于存储一些结构化数据（仅用于简单属性的对象）。
  > + __无序集合__：通过 intset（整数数集）、 哈希表（字典）实现其功能，核心能力就是对加入集合中的元素进行去重，相同元素的多次添加不会影响集合中的数据状态，同时支持集合的并、交、差等操作。
  > 使用场景有：共同好友，可能认识的人，数据去重等业务中。
  > + __有序集合__：利用压缩列表、跳跃表进行实现，与无序集合最大的区别是集合中的元素有序，通过为每个元素增加 `score` 属性保证有序性，同时允许不同元素可以存在相同的 `score`。
  > 使用场景主要有：滑动窗口、优先/延迟队列等。

+ redis的线程模型是怎样的？如何支持高并发，速度又为何快？
  > + 模型：redis 内部使用文件事件处理器并采用了单线程的方式进行实现，因此也叫做单线程模型。需要注意的是在 6.0 版本以后开始采用多线程模型，
  > 这里的多线程模型仅用来处理网络数据的读写和协议的解析（为了利用 IO 期间的 CPU 资源），redis 命令的执行方式依然采用单线程
  > （因为多线程反而会更加复杂，需要去控制key、 Lua、事务、LPUSH/LPOP所产生的并发问题）。
  > + 高并发和快的原因：redis 选择基于 epoll 的 IO 多路复用的方式实现非阻塞 IO 。数据的操作均在内存中完成（内存的处理速度众所周知的快！）， 
  > 选择简单的单线程方式进行数据操作，避免了多线程环境下的上下文切换和锁竞争。采用了 C 语言进行开发实现，而 C 语言程序对于系统而言执行起来更加高效！

+ Redis和Memcached有啥区别？
  > + __数据结构__：redis 拥有更多的数据接口，同时也提供更加丰富的数据操作，当我们需要进行复杂数据结构操作的时候 redis 是不错的选择！
  > + __集群能力__：redis 在 3.x 版本之后，就能够支持 cluster 模式，然而 memcached 没有原生的集群模式，依赖客户端实现对集群中分片数据的写入操作。
  > + __性能优势__：在进行数据存储时，redis 采用单核，而 memcached 采用多核。平均到每一个核上 redis 在存储小数据处时对 memcached 性能更高，
  > 而在 100k 以上的数据中，Memcached 性能要高于 Redis！

+ 跳跃表是一种怎样的数据结构？
  > 是一种随机化数据结构，查找、添加、删除操作都可以在对数期望时间下完成。
  > 跳跃表目前在 Redis 的唯一作用，就是作为有序集类型的底层数据结构（之一，另一个构成有序集的结构是字典）。
  > 为了满足自身的需求，Redis 基于 William Pugh 论文中描述的跳跃表进行了修改，包括：
  > + score 值可重复。
  > + 对比一个元素需要同时检查它的 score 和 member 。
  > + 每个节点带有高度为 1 层的后退指针，用于从表尾方向向表头方向迭代。

+ redis的过期策略和内存淘汰机制是怎样的？
  > 过期策略是定期删除、惰性删除；内存淘汰机制：1）不驱逐，写入报错、2）allkeys-lru（所有key找到最少使用）、3）allkeys-random（所有key随机删除）
  > 4）volatile-lru（设置过期的key中，找到最少使用）、5）volatile-random（设置过期key中，随机删除）、6）volatile-ttl（设置过期key中，更接近过期时间的删除）

+ redis数据持久化模式是怎样的？
  > + __RBD持久化__：对 redis 中的数据进行周期性的数据持久化，按照不同的时间段生成 RDB 文件。
  >   + `优点`：可以对生成的多个 RDB 文件进行云备份存储（上传文件至云服务器），RDB 数据文件很适合做数据冷备份。
  >          数据备份通过 fork 一个子进程进行数据备份，不会对 redis 对外的读写服务造成性能上的影响，依然可以保持高性能的服务。
  >          相对于 AOF 模式，当前模式的进行数据恢复的过程更快。
  >   + `缺点`：因为采用周期性的方式来备份数据，一般进行数据备份的时间间隔在 5min 左右（甚至更长），可能无法满足尽可能少地丢失数据的场景。
  >          当一个 fork 的子进程对数据进行快照文生成时，如果数据文件太大，可能会导致对客户端提供的服务造数毫秒，甚至数秒的停顿。
  >   
  > + __AOF持久化__：以 redis 中的每条写指令作为日志，采用追加写入的模式（append-only）写入日志文件中。在重启的过程中，通过重放这些命令来恢复数据。
  >   + `优点`：一般都是一秒执行一次 `fsync` 操作，相对于 RDB 能够更好地保证数据不丢失。
  >            通过 `append-only` 的方式写文件，没有任何磁盘寻址的开销，所以写入性能非常高。并且文件不易被破坏，即使文件尾部受损也很容易进行修复。
  >            即使日志文件较大出现后台重写操作时，也不会对客户端的读写性能造成影响，因为 `rewrite` log 会进行指令压缩，在压缩生成新文件的过程中，
  >            老的文件依然正常写入，当 `merge` 后的新文件 `ready` 后再进行新老文件交换即可。 
  >            通过可读较强的方式进行记录，这个特性非常适合做灾难性的误删除的紧急恢复，比如不小心执行了 `fushall` 命令，可以通过修改 AOF 文件，
  >            对命令进行删除，然后覆盖原来的文件即可修复这个错误操作。
  >   + `缺点`：对于一份相同的数据来说，AOF 的日志文件通常要比 RDB 的数据快照文件更大。AOF 模式下，redis 写操作的 QPS 会比 RDB 模式下的写 QPS 更低。
  >            会出现执行数据恢复的操作，却没能将数据一摸一样恢复回来的 bug 现象，不过这个问题可以在 `merge` 时通过当时内存中的数据进行指令的重新构建，
  >            而不是采用旧的指令日志。
  > redis 支持同时开启以上两种数据持久化备份方案，所以我们可以用 AOF 来保证数据不丢失，用作数据恢复的第一选择；用 RDB 来做不同程度的数据冷备份，
  > 当 AOF 文件都丢失或者损坏不可用的情况下，使用 RDB 来进行数据的快速恢复。

##### tomcat技术

+ 如何实现Servlet？
+ 如何看待jsp技术？
+ 核心组件有哪些，都有什么作用？

##### dubbo技术栈

+ 什么是rpc？
 > RPC 全称是 Remote Procedure Call 翻译过来就是远程过程调用。是一种通过网络从远程计算机程序上获取服务，而不需要了解代码的网络技术实现的一种协议。
 > 专业术语的解释读起来比较生硬，其实可以简单的理解为进行远程服务调用过程一种的协议，符合这个远程服务能力调用的技术实现都可以被称之为 RPC 技术。
 > RPC 强调的是过程调用，调用的过程对于用户（一般来说就是开发人员）来说是完全透明的，不需要关心其实现细节，可以像调用本次服务一样调用远程服务。
 > RPC 协议需要包含四个组件分别是：Client、ClientStub、Server、ServerStub。RPC 在分布式系统中有着非常广泛的应用，比如：
 > + 分布式系统网路通信
 > + 分布式子系统之间的服务治理
 > + 分布式负载均衡和流控
 > + 服务发现和注册
 > + 构建分布式调试环境

+ 什么是dubbo及特点？
  > dubbo 是一个 RPC 框架起源于 Alibaba 内部，目前已贡献给 apache 基金会进行孵化、迭代和维护。
  > 特点：分布式（多服务提供者和消费者）、高性能（基于 Netty 实现 NIO 通信）、透明化（可以像调用本地方法一样进行调用），
  > 同时提供了服务注册、服务发现、服务监控、服务降级等服务治理手段。

+ dubbo的启动过程是怎样的？
  > dubbo 服务启动是在 spring 容器启动完成后开始执行的，通过 spring 提供的 `BeanPostProcessor`、`BeanDefinitionRegistryPostProcessor`、`NamespaceHandlerSupport`、`ImportBeanDefinitionRegistrar` 等多个扩展点， 
  > 并结合 dubbo 提供多种配置方式将 dubbo 服务相关的 bean 注入 spring 和 dubbo 容器上下文当中，在这个环节中 `DubboSpringInitializer` 的作用很重要！
  > dubbo 通过监听 spring 容器加载完成的事件，通过 `DubboBootstrap` 启动类完成 dubbo 服务启动、注册、绑定等各个阶段的工作，保证 provider 和 consumer 能够正常服务！  

+ 如何看待Exchanger、Transporter、Exporter、Protocol等各个核心组件的关系？
+ dubbo如何解析xsd文件？如何实现与Spring进行关联整合？
+ dubbo与SpringCloud的区别？既有dubbo为啥会出现SpringCloud？
+ SPI机制了解吗？dubbo的SPI实现是怎样的，与JDK和Spring的有什么不同？
+ SPI所识别的目录有那些？
  > dubbo 的 SPI 功能接口的扩展实现类通过 `org.apache.dubbo.common.extension.LoadingStrategy` 来加载扩展点实现类，支持的加载目录如下：
  > + META-INF/dubbo/external/：`org.apache.dubbo.common.extension.DubboInternalLoadingStrategy`
  > + META-INF/services/：`org.apache.dubbo.common.extension.ServicesLoadingStrategy`
  > + META-INF/dubbo/：`org.apache.dubbo.common.extension.DubboLoadingStrategy`
  >
  > 每个目录都有一个独立的加载策略类，策略实现类中配置了当前策略的优先级，覆盖加载等信息（当扩展点实现类出现在多个目录下的扩展文件中时使用），

+ dubbo协议如何实现的？
+ dubbo服务暴露的原理与过程？
+ 如果注册中心挂了，dubbo还能工作吗？
  > 在生产中一般都采用 zookeeper 作为注册中心，基于 zookeeper 的高可用集群方案进行部署。
  > 如果真的出现了注册中心全部宕机的情况，dubbo 服务之间依然可以通过本地缓存的服务列表进行通信。

+ dubbo的集群容错策略有哪些？
+ dubbo适用的场景是啥？
  > 适合提供者少，消费者多的微服务场景中。

##### Spring技术栈

+ 如何看待和理解IOC和DI？
+ Spring容器的启动、加载过程？
+ Spring Bean实例化及依赖注入的过程，如何解决循环依赖问题？
  > 通过两级缓存进行避免，当 spring 加载实例化一个 bean 时，会首先从 1 级缓存中进行查找，如果没有找到目标 bean 会去 2 级缓存中进行寻找，
  > 如果还是没有找到，则意味这当前 bean 还没有进行实例化，于是 spring 容器会实例化目标 bean 并放入 2 级缓存中。
  > 当被 2 级缓存中的 bean 完成了属性赋值后（这个过程包含对依赖 bean 的赋值工作），则将该 bean 放入1 级缓存中。
  > 其实在 spring 的内部存在三级缓存，各个缓存的职责分别时：
  > + 1 级缓存：用于存在 spring 容器中成熟的 bean 实例，即就是一个完全的 bean 初始化和注入工作都已完成。
  > + 2 级缓存：这个缓存中的 bean 被称为早期 bean ，当前 bean 可能还没有完成属性值赋值、依赖注入、后置处理等流程。
  > + 3 级缓存：它的作用并不是为了解决循环依赖问题而存在，它主要时用来存储代理 bean 。当 spring 进行 bean 加载时，如果发现当前 bean 需要通过
  > 代理工厂进行创建，此时会将创建好的实例保存在 3 级缓存中，最终将赋值好的 bean 同步到 1 级缓存之中。
  > 
  > spring 本身只能解决单实例存在的循环引用问题。

+ Spring扩展机制？Spring的SPI如何实现的？
  > 

##### mybatis技术栈

+ #{}和${}的区别？
  > 虽然这两个都是 mybatis 提供的占位符，看起来时对 mapper 参数进行解析绑定映射处理但又不完全相同，
  > #{} 操作符在对 SQL 语句进行参数填充时采用了预占位符 `?` 的模式，参考 `java.sql.PreparedStatement` 的使用；
  > ${} 操作符对应的参数值，会直接解析进 SQL 语句中，在真正执行 Statement 前就已经完成了参数值填充。常用于对数据库函数传值，分库分表动态表名的传递等场景

+ 缓存机制的理解？

  > 缓存分两类：1）一级缓存，SqlSession级别的本地缓存；2）二级缓存，基于memcached、EHCache等实现，
  > 有点是解决了Session之间的缓存共享问题！

+ mapper加载的过程？
+ 如何实现分页？
+

##### 消息队列技术栈

+ 为什么需要消息队列？它能解决什么问题？

  > 消息队列的具有：__解耦__、__异步__、__削峰__优点：
  > + __解耦__：当我们某个业务同步调用多个不同服务接口时，新的迭代往往可能涉及加入新的子调用（RPC/http 等方式），都需要进行服务代码调整并更新发布。
  > 串行化的调用方式往往会因单接口超时导致整个业务执行一半而失败的现象，通过引入 MQ 解耦了业务间接口的强性依赖关系可以使服务响应加快，
  > 子业务的加入与下线更加便捷高效通过订阅MQ即可，减少了系统多次发布而产生的稳定性问题！
  > + __异步__：业务系统之间的调用关系多为强依赖，但是很多时候这些依赖之间的时效性要求没有那么高，为了时延性更低、处理速度更快往往会加入异步编程成分。
  > 例如当一个订单产生时，需要通知积分系统发送积分、快递系统进行派件等等流程，这些步骤完全可以通过异步完成。MQ 的加入可以将这种同步调用方式优化为异步模型！
  > + __削峰__：假设某个业务接口能够支撑的最高并发是 10k/qps，此时可能因为活动原因导致流量暴增接口所对应流量被放大了 10 倍，如此之高的流量很有可能将服务击垮致使
  > 整个业务处于瘫痪状态。这个时候如果引入 MQ 可以很好地解决这个问题，超过的流量可以由 MQ 的队列暂存等着慢慢消费即可，从而避免了服务瘫痪故障的风险！
  > 
  > 虽然消息存在那么多好处，它同样也逃不过事物双面性的 “魔咒”，存在这么几个缺点：__系统可用性降低__、__系统复杂度提高__、__一致性问题__！
  
+ 消息重复消费会存在什么问题？如何解决消息幂性？
  > 在使用消息队列对业务进行赋能的时候，必然会出现消息重复消费的问题，稍有不慎就会出现各种问题，例如：支付业务中多扣费、重复写导致的脏数据、积分多次发放等等问题。
  > 这些问题可大可小，一旦出现可能出现 P0 故障，如何避免才是关键！解决的办法其实有很多，例如：通过 redis 进行消息去重、建立消息去重表，通过异步任务扫面任务表处理、
  > 业务消费消息前检查、乐观锁控制等手段都可以避免。

+ RocketMQ为什么快？
  > 采用了零拷贝技术作为消息持久化刷盘的方案，commit-log 采用顺序读取的方式，避免了文件在读写过程中加入读写锁而导致的IO阻塞问题，
  > 同时采用了多主多从的高可用分布式架构，多 broker 部署流量负载分流决定了它可以支撑千万级的消费者

+ Kafka、ActiveMQ、RabbitMQ、RocketMQ 有什么优缺点？
  > 下面简单对比下这四个组件：
  > + __kafka__：吞吐量强可达到千万级，适用于日志、数据计算、批处理等场景，同 topic 下的分区（队列）数量过多（单机超过64）会影响性能，数据分散在各个机器的分区中。
  > 采用主从架构模式，毫秒级的响应时间，消息的并行度与分区（队列）有关
  > + __rocketmq__：吞吐量略低于 kafka， 消息不易丢失，适用于对消息可靠性要求高的场景，例如交易、订单等，同 topic 下的队列数量高于 kafka （单机最高5w），
  > 拥有独立的同步刷盘机制，而 kafka 不支持。采用多主多从的分布式架构，天然就是分布式消息！消息的并行度与消费线程数有关。
  > + __rabbitmq__：消息吞吐量处于百万级，优点是消息时延性可达到微秒级，基于主从做高可用并不是分布式消息队列，单个queue的数据指挥在一个节点中存储，
  > 开启集群模式后，一个queue的数据在各个节点复制都是全量数据。收到消息后暂存在内存中，消费过或过期的消息数据会清理，
  > 这一点不同于 kafka 和 rocketmq 的消息机制，虽然也支持磁盘持久化，但是会降低性能！
  > + __activemq__：很古老了，没有多少人使用了。
  > 
  > 综上所述，目前比较主流的就是 kafka 和 rabbitmq ，互联网大厂都在使用中，采用 kafka 进行数据分析计算、日志收集聚合，
  > 使用 rocketmq 作为业务解耦的消息中间件，消息不会在丢失！

##### xxl-job相关

##### 设计模式

+ 观察者模式
+ 代理模式
+ 访问者模式
+ 状态模式
+ 单例模式
+ 工厂模式

##### netty（会问吗？）

+ Reactor模型有哪些，各有什么特点？
  > reactor模型主要分为三类：
  > + __单线程__： acceptor和handler都为单线程，当单个请求处理过慢会导致后续请求被阻塞，导致IO吞吐性能下降。
  > + __多线程__：acceptor单线程而handler多线程，解决了单个请求慢而阻塞处理的问题，但是当并发请求量大的时候接受请求的线程就会出现瓶颈。
  > + __主从模式__：acceptor和handler都为多线程执行，可以很好的解决上述出现的两个IO性能问题，一般推荐这种模式

+ InternalThreadLocalMap如何实现的？与ThreadLocalMap有什么不同？
  > InternalThreadLocalMap 是 netty内部扩展实现了一个 threadLocal 模型。

+ 关于BossEventLoopGroup和WorkerEventLoopGroup的理解？
  > 它们的真实面貌就是线程池，不过 Boss 的职责是负责接受分发 Netty IO事件Netty，而 Worker 用于处理数据通道上的IO事件，各司其职又相互配合。
  > Netty 之所以采用两个不同的事件组进行隔离，避免了单一事件组单个IO线程阻塞导致整个服务出现吞吐下降的问题！

+ 对ChannelInboundHandler和ChannelOutboundHandler的理解？

  > 都是继承自ChannelHandler接口，Inbound用于从Channel读取数据，Outbound用于向Channel写数据，各自的职责不同！
  > 当我们需要对服务的输入/输出数据体进行包装、增强、加工时，通过自定义 Handler 并继承 ChannelInboundHandlerAdapter/ChannelOutboundHandlerAdapter 接口即可。
  > Netty 自身也提供了很多很有用的Handler组件供我们直接使用，例如：ByteToMessageCodec、ByteToMessageDecoder、MessageToByteEncoder、ChannelDuplexHandler等。
  > 在 dubbo 的 RPC 数据编解码的过程中，上述 Handler 的身影都有所出现，值得注意的是 ChannelDuplexHandler 是一个双工处理器，可以响应IO出入事件并做出回应！
 

##### 扩展及发散性问题

+ 如何设计一个秒杀功能？
+ 签到功能如何进行实现？
  > 通过使用 redis 中的 bitmap 对用户的签到天数进行标记。

+ 如何设计一个RPC框架？
  > 设计实现一个 PRC 框架首先需要符合 RPC 协议的规范，需要包含四个组件分别是：Client、ClientStub、Server、ServerStub。

+ 消息队列如何实现？
+ 怎么看待clickhouse与elasticsearch？
  > 存储结构不同，clickhouse基于列式存储，适用于大量数据计算的场景

+ serverless是什么？
+ 云原生是怎样的？
  > 云原生是一种构建和运行应用程序的方法论，是一套技术体系和方法论。
  > 实现云原生需要具备这四个要素：1）必须是微服务；2）必须实现容器化；3）支持 DevOps；4）必须满足持续交付。  

+ 了解过go吗？
  > 简单的运用过，通过go写过一个客户端程序，并发的性能更好，因为它基于协程实现并发处理

+ jdk8之后都有那些新特性？
  > 支持函数式编程lambda表达式；基于Stream的流式处理；Files/Path工具类的出现；接口默认方法定义

+ RocketMQ事件消息和普通消息有什么不同？
  > 事件消息侧重于已经发生过的每个事件所生出来的消息，它具有具象化、不可变、顺序性等特点。

+ 如何实现一个MQ系统
  > 需要从一下几个方面进行考虑：扩容机制的伸缩性、MQ的可用性（主从架构，舵主多住多从）、如何防止数据丢失（RocketMQ/Kafka的刷盘机制）
 
+ CPU 的 steal time 是什么？
  > steal time 是一种针对虚拟化环境中的CPU使用率指标，它表示虚拟机（VM）因为被宿主机（Host）上的其他进程所占用而无法使用CPU的时间。
  > 在虚拟化环境中，宿主机将物理CPU分配给多个虚拟机，每个虚拟机拥有自己的虚拟CPU。但是，当宿主机上的其他进程（例如其他虚拟机、宿主机上的系统进程等）需要使用CPU时，
  > 它们会抢占宿主机上的物理CPU，这会导致当前虚拟机无法使用虚拟CPU，从而产生了CPU steal time。
  > CPU steal time指标可以用来衡量虚拟机是否受到了宿主机上其他进程的影响，如果CPU steal time过高，可能会影响虚拟机的性能和稳定性。
  > 因此，对于那些需要对虚拟化环境中的CPU使用率进行优化的应用场景，需要关注CPU steal time指标！